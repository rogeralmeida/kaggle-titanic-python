{
 "metadata": {
  "name": "",
  "signature": "sha256:bf7eae6bf5afd3c6c9bdbed4a566dc9138e52e6913c4ed445c4db1278a129b76"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Titanic\n",
      "=================="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from pylab import *\n",
      "from matplotlib import pyplot as plt\n",
      "import csv as csv\n",
      "import numpy as np\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "\n",
      "def load_csv(file_name='train.csv'):\n",
      "\tcsv_file_object = csv.reader(open(file_name, 'rb')) #Load in the csv file\n",
      "\theader = csv_file_object.next() #Skip the fist line as it is a header\n",
      "\tthe_data=[] #Creat a variable called 'data'\n",
      "\tthe_ids=[]\n",
      "\tfor row in csv_file_object: #Skip through each row in the csv file\n",
      "\t\t\tthe_data.append(row[:]) #adding each row to the data variable\n",
      "\treturn np.array(the_data)\n",
      "\n",
      "def plot_xy(survived, died, x_index, y_index, y_label, x_label):\n",
      "    survived[survived == '']=-1.\n",
      "    died[died == '']=-1.\n",
      "    x = np.asarray(survived[:, x_index], dtype=float32)\n",
      "    y = np.asarray(survived[:, y_index], dtype=float32)\n",
      "    plt.plot(np.asarray(died[:, x_index], dtype=float32), np.asarray(died[:, y_index], dtype=float32), 'bo')\n",
      "    plt.plot(x, y, 'rx')\n",
      "    plt.ylabel(y_label)\n",
      "    plt.xlabel(x_label)\n",
      "    plt.autoscale(tight=False)\n",
      "    plt.show()\n",
      "\n",
      "def plot_survivor_death_bar(index, survivors, deaths):\n",
      "    plt.bar(index, survivors.shape[0], label=\"Survivors\")\n",
      "    plt.bar(index, deaths.shape[0], bottom=survivors.shape[0], color='r')\n",
      "    \n",
      "\n",
      "train_data = np.asarray(load_csv('src/train.csv'))\n",
      "\n",
      "survived = train_data[train_data[:,1]=='1']\n",
      "died = train_data[train_data[:, 1]=='0']\n",
      "\n",
      "#plotting dotted charts\n",
      "plot_xy(survived, died, 5, 6, 'Siblings/Spouses', 'Idade')\n",
      "plot_xy(survived, died, 5, 7, 'Parents/Children', 'Idade')\n",
      "\n",
      "#plotting bar charts\n",
      "plot_survivor_death_bar(0, survived, died)\n",
      "plot_survivor_death_bar(1, survived[survived[:, 4]=='female'], died[died[:, 4]=='female'])\n",
      "plot_survivor_death_bar(2, survived[survived[:, 4]=='male'], died[died[:, 4]=='male'])\n",
      "plot_survivor_death_bar(3, survived[survived[:, 4]==None], died[died[:, 4]==None])\n",
      "plt.xticks([0.4, 1.4, 2.4, 3.4], ('All', 'Female', 'Male', 'Unknow'))\n",
      "plt.ylabel('# people')\n",
      "plt.xlabel('Sex')\n",
      "plt.show()\n",
      "\n",
      "plot_survivor_death_bar(0, survived[survived[:, 2]=='1'], died[died[:, 2]=='1'])\n",
      "plot_survivor_death_bar(1, survived[survived[:, 2]=='2'], died[died[:, 2]=='2'])\n",
      "plot_survivor_death_bar(2, survived[survived[:, 2]=='3'], died[died[:, 2]=='3'])\n",
      "plot_survivor_death_bar(3, survived[survived[:, 2]==None], died[died[:, 2]==None])\n",
      "plt.xticks([0.4, 1.4, 2.4, 3.4], ('First', 'Second', 'Third', 'Unknow'))\n",
      "plt.ylabel('# people')\n",
      "plt.xlabel('Class')\n",
      "plt.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Port of Embark"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_survivor_death_bar(0, survived[survived[:, 11]=='C'], died[died[:, 11]=='C'])\n",
      "plot_survivor_death_bar(1, survived[survived[:, 11]=='Q'], died[died[:, 11]=='Q'])\n",
      "plot_survivor_death_bar(2, survived[survived[:, 11]=='S'], died[died[:, 11]=='S'])\n",
      "plot_survivor_death_bar(3, survived[survived[:, 11]==None], died[died[:, 11]==None])\n",
      "plt.xticks([0.4, 1.4, 2.4, 3.4], ('Cherbourg', 'Queenstown', 'Southampton', 'Unknow'))\n",
      "plt.ylabel('# people')\n",
      "plt.xlabel('Port of Embarkation')\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Super class to hipothesys.\n",
      "It defines common behavior and a common interface."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "class Hypothesis:\n",
      "\n",
      "  def __init__(self, train_data, validation_data):\n",
      "    self.trainY = self.extract_y(train_data)\n",
      "    self.trainX = self.extract_x(train_data)\n",
      "    self.validationY = self.extract_y(validation_data)\n",
      "    self.validationX = self.extract_x(validation_data)\n",
      "    self.trainX = preprocessing.scale(self.trainX)\n",
      "    self.validationX = preprocessing.scale(self.validationX)\n",
      "\n",
      "  def extract_y(self, data):\n",
      "    y = np.asarray(data[:, 1], dtype=np.float32)\n",
      "    return np.reshape(y, -1)\n",
      "  \n",
      "  #0   PassengerId\n",
      "  #1   Survived\n",
      "  #2   pclass          Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)             \n",
      "  #3   name            Name\n",
      "  #4   sex             Sex\n",
      "  #5   age             Age\n",
      "  #6   sibsp           Number of Siblings/Spouses Aboard\n",
      "  #7   parch           Number of Parents/Children Aboard\n",
      "  #8   ticket          Ticket Number\n",
      "  #9   fare            Passenger Fare\n",
      "  #10  cabin           Cabin\n",
      "  #11  embarked        Port of Embarkation\n",
      "  def extract_x(self, data, columns_2_remove=[0, 1, 3, 8, 10]):\n",
      "    relevant_features = np.delete(data, columns_2_remove, 1)\n",
      "    relevant_features = self.convert_texts(relevant_features)\n",
      "    relevant_features=np.asarray(relevant_features, dtype=np.float32)\n",
      "    return relevant_features\n",
      "\n",
      "  def convert_texts(self, data):\n",
      "    data[data == 'male']=0.\n",
      "    data[data == 'female']=1.\n",
      "    data[data == '']=-1.\n",
      "    data[data == 'C']=0.\n",
      "    data[data == 'Q']=1.\n",
      "    data[data == 'S']=2.\n",
      "    return data\n",
      "\n",
      "  def train(self):\n",
      "    highest_precision = 0\n",
      "    for local_penalty in ['l1', 'l2']:\n",
      "      for local_tol in np.arange(0.01, 2.5, 0.05):\n",
      "        for local_c in np.arange(0.5, 5.5, 0.5):\n",
      "          for local_fit_intercept in [True, False]:\n",
      "            for local_intercept_scaling in np.arange(0.1, 3, 0.5):\n",
      "              for local_loss in ['l1', 'l2']:\n",
      "                if self.valid_parameters(local_c, local_loss, local_penalty, local_tol, local_fit_intercept, local_intercept_scaling):\n",
      "                  hipothesys = self.create_hipothesys(local_c, local_loss, local_penalty, local_tol, local_fit_intercept, local_intercept_scaling)\n",
      "                  precision = self.calculatePrecision(hipothesys)\n",
      "                  if precision > highest_precision:\n",
      "                    print \"Nova melhor precisao atual: {0}\".format(precision)    \n",
      "                    self.hipothesys = hipothesys\n",
      "                    self.precision = precision\n",
      "                    highest_precision = precision\n",
      "\n",
      "\n",
      "  def score(self):\n",
      "    return self.precision\n",
      "\n",
      "  def calculatePrecision(self, hipothesys):\n",
      "    return hipothesys.score(self.validationX, self.validationY) \n",
      "\n",
      "  def predict(self, test_data):\n",
      "    x = self.extract_x(test_data, [0, 2, 7, 9])\n",
      "    predicted = self.hipothesys.predict(x)\n",
      "    resultado = np.empty([test_data.shape[0], 2], dtype=int)\n",
      "    resultado[:, 0] = test_data[:, 0]\n",
      "    resultado[:, 1] = predicted.astype('int')\n",
      "    return resultado\n",
      "\n",
      "  def __str__(self):\n",
      "    return \"{0} with params {1}\".format(self.hipothesys, self.hipothesys.get_params())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LinearSVCHipotesys(Hypothesis):\n",
      "\n",
      "\tdef valid_parameters(self, c, loss, penalty, tol, fit_intercept, intercept_scaling):\n",
      "        #penalty='l2' and ploss='l1' is only supported when dual='true'\n",
      "\t\tif (penalty == 'l1' and loss == 'l1') or (penalty == 'l2' and loss == 'l1'):\n",
      "\t\t\treturn False\n",
      "\t\telse:\n",
      "\t\t\treturn True\n",
      "\n",
      "\tdef create_hipothesys(self, c, loss, penalty, tol, fit_intercept, intercept_scaling):\n",
      "\t\thipotesys = LinearSVC(C=c, loss=loss, penalty=penalty, tol=tol, fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, dual=False, verbose=0)\n",
      "\t\treturn hipotesys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegressionHipotesys(Hypothesis):\n",
      "\n",
      "\tdef valid_parameters(self, c, loss, penalty, tol, fit_intercept, intercept_scaling):\n",
      "\t\tif penalty == 'l1' and loss == 'l1':\n",
      "\t\t\treturn False\n",
      "\t\telse:\n",
      "\t\t\treturn True\n",
      "\n",
      "\tdef create_hipothesys(self, c, loss, penalty, tol, fit_intercept, intercept_scaling):\n",
      "\t\thypothesis = LogisticRegression(C=c, penalty=penalty, tol=tol, fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, dual=False)\n",
      "\t\treturn hypothesis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SVCHipotesys(Hypothesis):\n",
      "\n",
      "\tdef train(self):\n",
      "\t\thighest_precision = 0\n",
      "\t\tfor c in np.arange(0.1, 2.5, 0.1):\n",
      "\t\t\thipothesys = SVC(C=c, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, \n",
      "                             probability=False, tol=0.0001, cache_size=200, class_weight=None, verbose=False, \n",
      "                             max_iter=-1, random_state=None)\n",
      "\t\t\tprecision = self.calculatePrecision(hipothesys)\n",
      "\t\t\tif precision > highest_precision:\n",
      "\t\t\t\tself.hipothesys = hipothesys \n",
      "\t\t\t\tself.precision = precision\n",
      "\t\t\t\thighest_precision = precision"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RandomForestHipothesys(Hypothesis):\n",
      "    def train(self):\n",
      "        highest_precision = 0\n",
      "        for n_estimator in np.arange(1, 20, 1):\n",
      "            for criterion in ['gini', 'entropy']:\n",
      "                hipothesys = RandomForestClassifier(n_estimators=n_estimator, criterion=criterion, max_depth=None, min_samples_split=2, \n",
      "                                                    min_samples_leaf=1, max_features='auto', bootstrap=True, oob_score=False, \n",
      "                                                    n_jobs=1, random_state=None, verbose=0, min_density=None, compute_importances=None)\n",
      "                precision = self.calculatePrecision(hipothesys)\n",
      "                if precision > highest_precision:\n",
      "                    precision = self.calculatePrecision(hipothesys)\n",
      "                    self.hipothesys = hipothesys\n",
      "                    self.precision = precision\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.shuffle(train_data)\n",
      "import math\n",
      "validation_size = math.floor(train_data.shape[0] * 0.2)\n",
      "validation_data = np.asarray(train_data[:validation_size, :])\n",
      "train_data = np.asarray(train_data[validation_size:, :])\n",
      "\n",
      "hipotesys_list = []\n",
      "hipotesys_list.append(RandomForestHipothesys(train_data, validation_data))\n",
      "hipotesys_list.append(LogisticRegressionHipotesys(train_data, validation_data))\n",
      "hipotesys_list.append(LinearSVCHipotesys(train_data, validation_data))\n",
      "#hipotesys_list.append(SVCHipotesys(train_data, validation_data))\n",
      "winner_hypothesis = None\n",
      "highest_score = 0.0\n",
      "for h in hipotesys_list:\n",
      "\th.train()\n",
      "\tscore = h.score()\n",
      "\tif score > highest_score:\n",
      "\t\twinner_hypothesis = h\n",
      "\t\thighest_score = score\n",
      "\n",
      "print \"======== Winner Hipothesys =============\"\n",
      "print winner_hypothesis\n",
      "print \"========================================\"\n",
      "print \"Precision against validation data:\"\n",
      "print highest_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data = load_csv('src/test.csv')\n",
      "final_result = winner_hypothesis.predict(test_data)\n",
      "np.savetxt('final_result.csv', final_result.astype('int'), fmt=\"%.1d\", delimiter=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}